{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import scipy.io\n",
    "import math\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import spatial\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import spatial\n",
    "import gc\n",
    "import scipy.io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id gender masterCategory subCategory  articleType baseColour  season  \\\n",
      "0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n",
      "1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n",
      "2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n",
      "3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n",
      "4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n",
      "\n",
      "     year   usage                             productDisplayName  \n",
      "0  2011.0  Casual               Turtle Check Men Navy Blue Shirt  \n",
      "1  2012.0  Casual             Peter England Men Party Blue Jeans  \n",
      "2  2016.0  Casual                       Titan Women Silver Watch  \n",
      "3  2011.0  Casual  Manchester United Men Solid Black Track Pants  \n",
      "4  2012.0  Casual                          Puma Men Grey T-shirt  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 6044: expected 10 fields, saw 11\\nSkipping line 6569: expected 10 fields, saw 11\\nSkipping line 7399: expected 10 fields, saw 11\\nSkipping line 7939: expected 10 fields, saw 11\\nSkipping line 9026: expected 10 fields, saw 11\\nSkipping line 10264: expected 10 fields, saw 11\\nSkipping line 10427: expected 10 fields, saw 11\\nSkipping line 10905: expected 10 fields, saw 11\\nSkipping line 11373: expected 10 fields, saw 11\\nSkipping line 11945: expected 10 fields, saw 11\\nSkipping line 14112: expected 10 fields, saw 11\\nSkipping line 14532: expected 10 fields, saw 11\\nSkipping line 15076: expected 10 fields, saw 12\\nSkipping line 29906: expected 10 fields, saw 11\\nSkipping line 31625: expected 10 fields, saw 11\\nSkipping line 33020: expected 10 fields, saw 11\\nSkipping line 35748: expected 10 fields, saw 11\\nSkipping line 35962: expected 10 fields, saw 11\\nSkipping line 37770: expected 10 fields, saw 11\\nSkipping line 38105: expected 10 fields, saw 11\\nSkipping line 38275: expected 10 fields, saw 11\\nSkipping line 38404: expected 10 fields, saw 12\\n'\n"
     ]
    }
   ],
   "source": [
    "styles = pd.read_csv('.\\\\fashion-dataset\\\\styles.csv', error_bad_lines=False)\n",
    "print(styles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model = resnet50.ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Navy Blue', 'Blue', 'Silver', 'Black', 'Grey', 'Green', 'Purple',\n",
       "       'White', 'Beige', 'Brown', 'Bronze', 'Teal', 'Copper', 'Pink',\n",
       "       'Off White', 'Maroon', 'Red', 'Khaki', 'Orange', 'Coffee Brown',\n",
       "       'Yellow', 'Charcoal', 'Gold', 'Steel', 'Tan', 'Multi', 'Magenta',\n",
       "       'Lavender', 'Sea Green', 'Cream', 'Peach', 'Olive', 'Skin',\n",
       "       'Burgundy', 'Grey Melange', 'Rust', 'Rose', 'Lime Green', 'Mauve',\n",
       "       'Turquoise Blue', 'Metallic', 'Mustard', 'Taupe', 'Nude',\n",
       "       'Mushroom Brown', nan, 'Fluorescent Green'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = styles['baseColour'].unique()\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d5b3f15680ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marticle\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Tshirts'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mtshirts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstyles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'articleType'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0marticle\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstyles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'baseColour'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtshirts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0marticles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'articleType'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0marticle\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstyles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'baseColour'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# shirts_navyblue = styles[(styles['articleType'] == 'Shirts') & (styles['baseColour'] == 'Navy Blue')]['id'].to_numpy()\n",
    "# shirts_blue = styles[(styles['articleType'] == 'Shirts') & (styles['baseColour'] == 'Blue')]['id'].to_numpy()\n",
    "# shirts_black = styles[(styles['articleType'] == 'Shirts') & (styles['baseColour'] == 'Black')]['id'].to_numpy()\n",
    "# shirts_grey = styles[(styles['articleType'] == 'Shirts') & (styles['baseColour'] == 'Grey')]['id'].to_numpy()\n",
    "# shirts_green = styles[(styles['articleType'] == 'Shirts') & (styles['baseColour'] == 'Green')]['id'].to_numpy()\n",
    "# shirts_purple = styles[(styles['articleType'] == 'Shirts') & (styles['baseColour'] == 'Purple')]['id'].to_numpy()\n",
    "# shirts_white = styles[(styles['articleType'] == 'Shirts') & (styles['baseColour'] == 'White')]['id'].to_numpy()\n",
    "# shirts = styles[(styles['articleType'] == 'Shirts') & (styles['baseColour'] == 'Beige')]\n",
    "\n",
    "articles = []\n",
    "for i, color in enumerate(colors):    \n",
    "    for article in ['Tshirts',\n",
    "                    'Jeans',\n",
    "                    'Sports Shoes']:\n",
    "        x = styles[(styles['articleType'] == article) & (styles['baseColour'] == color)].shape[0]\n",
    "        if x >= 100:\n",
    "            if (article == 'Tshirts'):\n",
    "                tshirts = styles[(styles['articleType'] == article) & (styles['baseColour'] == color)]['id'].to_numpy()\n",
    "                print(tshirts.head(100).shape)\n",
    "                continue\n",
    "            articles.append(styles[(styles['articleType'] == article) & (styles['baseColour'] == color)]['id'].to_numpy())\n",
    "            print(article, color)\n",
    "print(len(articles))\n",
    "print(sum(map(len, articles)))\n",
    "\n",
    "# shirts_navyblue.shape, shirts_blue.shape, shirts_black.shape, shirts_grey.shape, shirts_green.shape, shirts_purple.shape, shirts_white.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '.\\\\fashion-dataset\\\\images\\\\'\n",
    "\n",
    "IMG_SIZE = 224\n",
    "LIMIT_IMAGES = 196\n",
    "NUM_OUTPUTS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(names):\n",
    "    imgs = []\n",
    "    for i, image_name in enumerate(tqdm(names)):\n",
    "#         if i% 50 == 0 :\n",
    "#             print(f\"Loading Image {i}\")\n",
    "        try:\n",
    "            img = image.load_img(f'{image_path}{image_name}.jpg', target_size=(IMG_SIZE, IMG_SIZE))\n",
    "        except:\n",
    "            img = None\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = np.array(img)\n",
    "        imgs.append(img)\n",
    "    return np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Loading...\")\n",
    "# shirts_navyblue_images = load_imgs(shirts_navyblue[:LIMIT_IMAGES])\n",
    "# shirts_blue_images = load_imgs(shirts_blue[:LIMIT_IMAGES])\n",
    "# shirts_black_images = load_imgs(shirts_black[:LIMIT_IMAGES])\n",
    "# shirts_grey_images = load_imgs(shirts_grey[:LIMIT_IMAGES])\n",
    "# shirts_green_images = load_imgs(shirts_green[:LIMIT_IMAGES])\n",
    "# shirts_purple_images = load_imgs(shirts_purple[:LIMIT_IMAGES])\n",
    "# shirts_white_images = load_imgs(shirts_white[:LIMIT_IMAGES])\n",
    "# shirts_navyblue_images.shape, shirts_blue_images.shape, shirts_black_images.shape, shirts_grey_images.shape, shirts_green_images.shape, shirts_purple_images.shape, shirts_white_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Loading...\")\n",
    "# shirts_navyblue_images = load_imgs(shirts_navyblue)\n",
    "# shirts_blue_images = load_imgs(shirts_blue)\n",
    "# shirts_black_images = load_imgs(shirts_black)\n",
    "# shirts_grey_images = load_imgs(shirts_grey)\n",
    "# shirts_green_images = load_imgs(shirts_green)\n",
    "# shirts_purple_images = load_imgs(shirts_purple)\n",
    "# shirts_white_images = load_imgs(shirts_white)\n",
    "# shirts_navyblue_images.shape, shirts_blue_images.shape, shirts_black_images.shape, shirts_grey_images.shape, shirts_green_images.shape, shirts_purple_images.shape, shirts_white_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 438/438 [00:56<00:00,  7.82it/s]\n",
      "  0%|                                                                              | 1/1046 [00:00<02:21,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1046/1046 [02:12<00:00,  7.87it/s]\n",
      "  0%|                                                                                       | 0/446 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████▌                                          | 200/446 [00:25<00:25,  9.47it/s]"
     ]
    }
   ],
   "source": [
    "new_articles = []\n",
    "for i, article in enumerate(articles):\n",
    "    new_articles.append(load_imgs(article))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_articles = []\n",
    "test_articles = []\n",
    "\n",
    "for new_article in new_articles:\n",
    "    train_article, test_article, _, _ = train_test_split(new_article, np.repeat(0, new_article.shape[0]), test_size=0.2)\n",
    "    train_articles.append(train_article)\n",
    "    test_articles.append(test_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_shirts = []\n",
    "# test_shirts = []\n",
    "\n",
    "# for shirt in shirts:\n",
    "#     train_shirt, test_shirt, _, _ = train_test_split(shirt, np.repeat(0, shirt.shape[0]), test_size=0.2)\n",
    "#     train_shirts.append(train_shirt)\n",
    "#     test_shirts.append(test_shirt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_shirts_navyblue_images, test_shirts_navyblue_images, _, _ = train_test_split(shirts_navyblue_images, np.repeat(0, shirts_navyblue_images.shape[0]), test_size = 0.2)\n",
    "# train_shirts_blue_images, test_shirts_blue_images, _, _ = train_test_split(shirts_blue_images, np.repeat(0, shirts_blue_images.shape[0]), test_size = 0.2)\n",
    "# train_shirts_black_images, test_shirts_black_images, _, _ = train_test_split(shirts_black_images, np.repeat(0, shirts_black_images.shape[0]), test_size = 0.2)\n",
    "# train_shirts_grey_images, test_shirts_grey_images, _, _ = train_test_split(shirts_grey_images, np.repeat(0, shirts_grey_images.shape[0]), test_size = 0.2)\n",
    "# train_shirts_green_images, test_shirts_green_images, _, _ = train_test_split(shirts_green_images, np.repeat(0, shirts_green_images.shape[0]), test_size = 0.2)\n",
    "# train_shirts_purple_images, test_shirts_purple_images, _, _ = train_test_split(shirts_purple_images, np.repeat(0, shirts_purple_images.shape[0]), test_size = 0.2)\n",
    "# train_shirts_white_images, test_shirts_white_images, _, _ = train_test_split(shirts_white_images, np.repeat(0, shirts_white_images.shape[0]), test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(imgs):\n",
    "    processed_batch = preprocess_input(imgs, mode=\"caffe\")\n",
    "    return resnet50_model.predict(processed_batch)\n",
    "\n",
    "def get_average_vector(imgs):\n",
    "    vectors = get_vectors(imgs)\n",
    "    print(vectors.shape)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "def closeness(a, b):\n",
    "#     print(a.shape)\n",
    "#     print(b.shape)\n",
    "    return 1 - spatial.distance.cosine(a, b)\n",
    "\n",
    "def closest(vector, compared_to):\n",
    "    best = -5\n",
    "    best_idx = -1\n",
    "#     print(compared_to.shape)\n",
    "    for i, cmp in enumerate(compared_to):\n",
    "        c = closeness(vector, cmp)\n",
    "        if c > best:\n",
    "            best_idx = i\n",
    "            best = c\n",
    "    return best_idx, best\n",
    "\n",
    "def b_closest(vectors, compared_to):\n",
    "    return np.array([closest(vector, compared_to)[0] for vector in vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Test And Train Sets\n",
    "train_X = np.concatenate(train_articles, axis = 0)\n",
    "train_Y = np.repeat(list(range(len(new_articles))), [train_article.shape[0] for train_article in train_articles], axis = 0)\n",
    "\n",
    "train_vecs = get_vectors(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get Test And Train Sets\n",
    "# train_X = np.concatenate((\n",
    "#     train_shirts_navyblue_images,\n",
    "#     train_shirts_blue_images,\n",
    "#     train_shirts_black_images,\n",
    "#     train_shirts_grey_images,\n",
    "#     train_shirts_green_images,\n",
    "#     train_shirts_purple_images,\n",
    "#     train_shirts_white_images,\n",
    "# ), axis = 0)\n",
    "# train_Y = np.repeat((0, 1, 2, 3, 4, 5, 6), (\n",
    "#     train_shirts_navyblue_images.shape[0],\n",
    "#     train_shirts_blue_images.shape[0],\n",
    "#     train_shirts_black_images.shape[0],\n",
    "#     train_shirts_grey_images.shape[0],\n",
    "#     train_shirts_green_images.shape[0],\n",
    "#     train_shirts_purple_images.shape[0],\n",
    "#     train_shirts_white_images.shape[0],\n",
    "# ), axis = 0)\n",
    "\n",
    "# train_vecs = get_vectors(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Test And Train Sets\n",
    "test_X = np.concatenate(test_articles, axis = 0)\n",
    "test_Y = np.repeat(list(range(len(new_articles))), [test_article.shape[0] for test_article in test_articles], axis = 0)\n",
    "\n",
    "test_vecs = get_vectors(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get Test And Train Sets\n",
    "# test_X = np.concatenate((\n",
    "#     test_shirts_navyblue_images,\n",
    "#     test_shirts_blue_images,\n",
    "#     test_shirts_black_images,\n",
    "#     test_shirts_grey_images,\n",
    "#     test_shirts_green_images,\n",
    "#     test_shirts_purple_images,\n",
    "#     test_shirts_white_images,\n",
    "# ), axis = 0)\n",
    "# test_Y = np.repeat((0, 1, 2, 3, 4, 5, 6), (\n",
    "#     test_shirts_navyblue_images.shape[0],\n",
    "#     test_shirts_blue_images.shape[0],\n",
    "#     test_shirts_black_images.shape[0],\n",
    "#     test_shirts_grey_images.shape[0],\n",
    "#     test_shirts_green_images.shape[0],\n",
    "#     test_shirts_purple_images.shape[0],\n",
    "#     test_shirts_white_images.shape[0],\n",
    "# ), axis = 0)\n",
    "\n",
    "# test_vecs = get_vectors(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, trainy = shuffle(train_vecs, train_Y)\n",
    "trainx.shape, trainy.shape\n",
    "tx, vx, ty, vy = train_test_split(trainx, trainy, test_size = 0.2)\n",
    "testx, testy = test_vecs.copy(), test_Y.copy()\n",
    "tx.shape, ty.shape, vx.shape, vy.shape, testx.shape, testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "tx = scaler.fit_transform(tx)\n",
    "vx = scaler.transform(vx)\n",
    "testx = scaler.transform(testx)\n",
    "\n",
    "tx.shape, ty.shape, vx.shape, vy.shape, testx.shape, testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.00007\n",
    "NUM_FEATURES = 1000\n",
    "NUM_CLASSES = NUM_OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MulticlassClassification(nn.Module):\n",
    "#     def __init__(self, num_feature, num_class):\n",
    "#         super(MulticlassClassification, self).__init__()\n",
    "        \n",
    "#         self.layer_1 = nn.Linear(num_feature, 512)\n",
    "#         self.layer_2 = nn.Linear(512, 128)\n",
    "#         self.layer_3 = nn.Linear(128, 64)\n",
    "#         self.layer_out = nn.Linear(64, num_class) \n",
    "        \n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(p=0.2)\n",
    "#         self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "#         self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "#         self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.layer_1(x)\n",
    "#         x = self.batchnorm1(x)\n",
    "#         x = self.relu(x)\n",
    "        \n",
    "#         x = self.layer_2(x)\n",
    "#         x = self.batchnorm2(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.dropout(x)\n",
    "        \n",
    "#         x = self.layer_3(x)\n",
    "#         x = self.batchnorm3(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.dropout(x)\n",
    "        \n",
    "#         x = self.layer_out(x)\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_model = MulticlassClassification(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
    "# torch_model.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(torch_model.parameters(), lr=LEARNING_RATE)\n",
    "# print(torch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multi_acc(y_pred, y_test):\n",
    "#     y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "#     _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    \n",
    "#     correct_pred = (y_pred_tags == y_test).float()\n",
    "#     acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "#     acc = torch.round(acc) * 100\n",
    "    \n",
    "#     return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ClassifierDataset(Dataset):\n",
    "    \n",
    "#     def __init__(self, X_data, y_data):\n",
    "#         self.X_data = X_data\n",
    "#         self.y_data = y_data\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "#     def __len__ (self):\n",
    "#         return len(self.X_data)\n",
    "\n",
    "\n",
    "# train_dataset = ClassifierDataset(torch.from_numpy(tx).float(), torch.from_numpy(ty).long())\n",
    "# val_dataset = ClassifierDataset(torch.from_numpy(vx).float(), torch.from_numpy(vy).long())\n",
    "# test_dataset = ClassifierDataset(torch.from_numpy(testx).float(), torch.from_numpy(testy).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(dataset=train_dataset,\n",
    "#                           batch_size=BATCH_SIZE\n",
    "# )\n",
    "# val_loader = DataLoader(dataset=val_dataset, batch_size=1)\n",
    "# test_loader = DataLoader(dataset=test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Begin training.\")\n",
    "# for e in tqdm(range(1, EPOCHS+1)):\n",
    "#     # TRAINING\n",
    "#     train_epoch_loss = 0\n",
    "#     train_epoch_acc = 0\n",
    "#     torch_model.train()\n",
    "#     for X_train_batch, y_train_batch in train_loader:\n",
    "#         X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         y_train_pred = torch_model(X_train_batch)\n",
    "        \n",
    "#         train_loss = criterion(y_train_pred, y_train_batch)\n",
    "#         train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "        \n",
    "#         train_loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         train_epoch_loss += train_loss.item()\n",
    "#         train_epoch_acc += train_acc.item()\n",
    "        \n",
    "        \n",
    "#     # VALIDATION    \n",
    "#     with torch.no_grad():\n",
    "        \n",
    "#         val_epoch_loss = 0\n",
    "#         val_epoch_acc = 0\n",
    "        \n",
    "#         torch_model.eval()\n",
    "#         for X_val_batch, y_val_batch in val_loader:\n",
    "#             X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            \n",
    "#             y_val_pred = torch_model(X_val_batch)\n",
    "                        \n",
    "#             val_loss = criterion(y_val_pred, y_val_batch)\n",
    "#             val_acc = multi_acc(y_val_pred, y_val_batch)\n",
    "            \n",
    "#             val_epoch_loss += val_loss.item()\n",
    "#             val_epoch_acc += val_acc.item()\n",
    "#             loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "#     loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "#     accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "#     accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
    "                              \n",
    "    \n",
    "#     print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(n_estimators=400, learning_rate=1)\n",
    "abcm = abc.fit(trainx, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = abc.predict(train_vecs)\n",
    "acc = accuracy_score(train_Y, preds)\n",
    "print(f\"In sample Accuracy: {acc}\")\n",
    "\n",
    "print(classification_report(train_Y, preds))\n",
    "\n",
    "preds = abc.predict(test_vecs)\n",
    "acc = accuracy_score(test_Y, preds)\n",
    "print(f\"Out of sample Accuracy: {acc}\")\n",
    "\n",
    "print(classification_report(test_Y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(abc, open('ada-vvlarge-964.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model.save('k.h5')\n",
    "model_json = resnet50_model.to_json()\n",
    "with open(\"kk.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6c597414f44d478071a77037a3db2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_img = load_imgs(['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = get_vectors(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = abc.predict(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3181, 1000), (3181,), (796, 1000), (796,), (1001, 1000), (1001,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx, trainy = shuffle(train_vecs, train_Y)\n",
    "trainx.shape, trainy.shape\n",
    "tx, vx, ty, vy = train_test_split(trainx, trainy, test_size = 0.2)\n",
    "testx, testy = test_vecs.copy(), test_Y.copy()\n",
    "tx.shape, ty.shape, vx.shape, vy.shape, testx.shape, testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3181, 1000), (3181,), (796, 1000), (796,), (1001, 1000), (1001,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx2, trainy2 = shuffle(train_vecs, train_Y)\n",
    "trainx2.shape, trainy2.shape\n",
    "tx2, vx2, ty2, vy2 = train_test_split(trainx, trainy, test_size = 0.2)\n",
    "testx2, testy2 = test_vecs.copy(), test_Y.copy()\n",
    "tx2.shape, ty2.shape, vx2.shape, vy2.shape, testx2.shape, testy2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3181, 1000), (3181,), (796, 1000), (796,), (1001, 1000), (1001,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "tx2 = scaler.fit_transform(tx2)\n",
    "vx2 = scaler.transform(vx2)\n",
    "testx2 = scaler.transform(testx2)\n",
    "\n",
    "tx2.shape, ty2.shape, vx2.shape, vy2.shape, testx2.shape, testy2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.00007\n",
    "NUM_FEATURES = 1000\n",
    "NUM_CLASSES = NUM_OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassClassification2(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MulticlassClassification2, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_feature, 512)\n",
    "        self.layer_2 = nn.Linear(512, 128)\n",
    "        self.layer_3 = nn.Linear(128, 256)\n",
    "        self.layer_4 = nn.Linear(256, 64)\n",
    "        self.layer_out = nn.Linear(64, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(256)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_4(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MulticlassClassification2(\n",
      "  (layer_1): Linear(in_features=1000, out_features=512, bias=True)\n",
      "  (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (layer_3): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (layer_4): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch_model2 = MulticlassClassification2(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
    "torch_model2.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(torch_model2.parameters(), lr=LEARNING_RATE)\n",
    "print(torch_model2)\n",
    "\n",
    "\n",
    "\n",
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc) * 100\n",
    "    \n",
    "    return acc\n",
    "\n",
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_dataset = ClassifierDataset(torch.from_numpy(tx).float(), torch.from_numpy(ty).long())\n",
    "val_dataset = ClassifierDataset(torch.from_numpy(vx).float(), torch.from_numpy(vy).long())\n",
    "test_dataset = ClassifierDataset(torch.from_numpy(testx).float(), torch.from_numpy(testy).long())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=1)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1)\n",
    "\n",
    "train_dataset2 = ClassifierDataset(torch.from_numpy(tx2).float(), torch.from_numpy(ty2).long())\n",
    "val_dataset2 = ClassifierDataset(torch.from_numpy(vx2).float(), torch.from_numpy(vy2).long())\n",
    "test_dataset2 = ClassifierDataset(torch.from_numpy(testx2).float(), torch.from_numpy(testy2).long())\n",
    "\n",
    "train_loader2 = DataLoader(dataset=train_dataset2, batch_size=BATCH_SIZE)\n",
    "val_loader2 = DataLoader(dataset=val_dataset2, batch_size=1)\n",
    "test_loader2 = DataLoader(dataset=test_dataset2, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a136df956d6c4a95916dd1473fb5a78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at C:/cb/pytorch_1000000000000/work/aten/src\\THC/THCTensorMathReduce.cuh:531",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-e85f863738cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmulti_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-3a37e449af33>\u001b[0m in \u001b[0;36mmulti_acc\u001b[1;34m(y_pred, y_test)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmulti_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0my_pred_softmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_tags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_softmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mcorrect_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_pred_tags\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at C:/cb/pytorch_1000000000000/work/aten/src\\THC/THCTensorMathReduce.cuh:531"
     ]
    }
   ],
   "source": [
    "print(\"Begin training.\")\n",
    "for e in tqdm(range(1, EPOCHS+1)):\n",
    "    gc.collect()\n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    torch_model2.train()\n",
    "    for X_train_batch, y_train_batch in train_loader2:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_train_pred = torch_model2(X_train_batch)\n",
    "        \n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "        \n",
    "        \n",
    "    # VALIDATION    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "        \n",
    "        torch_model2.eval()\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            \n",
    "            y_val_pred = torch_model2(X_val_batch)\n",
    "                        \n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_acc = multi_acc(y_val_pred, y_val_batch)\n",
    "            \n",
    "            val_epoch_loss += val_loss.item()\n",
    "            val_epoch_acc += val_acc.item()\n",
    "            loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
    "                              \n",
    "    gc.collect()\n",
    "    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, trainy = shuffle(train_vecs, train_Y)\n",
    "# trainx = np.expand_dims(trainx, axis=1)\n",
    "trainx.shape, trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=1000, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_model = estimator.fit(trainx, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = estimator.predict(train_vecs)\n",
    "acc = accuracy_score(train_Y, preds)\n",
    "print(f\"In sample Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = estimator.predict(test_vecs)\n",
    "acc = accuracy_score(test_Y, preds)\n",
    "print(f\"Out of sample Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.model.save('keras-vlarge-963.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learning-keras] *",
   "language": "python",
   "name": "conda-env-learning-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
